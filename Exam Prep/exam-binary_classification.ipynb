{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIT821 Software Engineering for AI systems - exam 2020-08-17\n",
    "\n",
    "\n",
    "### Assignement: Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Name, e-mail:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Assignement description\n",
    "\n",
    "A `Breast Cancer Winsconsin` dataset from \n",
    "University of Wisconsin  has been loaded for you in this Notebook from `sklearn.datasets` module. This dataset can be used to predict malignancy in breast cancer and contains 569 training examples with two classes (malignant and benign) in target 'Diagnosis' column. There are 30 features that describe characteristics of the cell nuclei present in the scanned images useful to discriminate benign from malignant lumps.\n",
    "\n",
    "You are required to implement a **Regularized Logistic Regression** classifier. The classifier is used to predict if a new patient has a probability of developing malignancy or not, basing on the the data.\n",
    "\n",
    "The first column of the dataset corresponds to the patient ID, while the last column represents the diagnosis (the outcome can be “Benign” or “Malignant” based on the type of diagnosis reported).\n",
    "\n",
    "Brief overview of dataset:\n",
    "-  Class (Diagnosis): \n",
    "      - malignant: 1\n",
    "      - benign: 0\n",
    "- Features are :\n",
    "    - ID Number \n",
    "    - radius, texture, perimeter, area, smoothness, compactness, concavity, concave points, symmetry, fractal dimension (of each its computed mean-10 features, standard error-10 features and mean of three largest values-10 features) \n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next subsequent three cells implements code to import required libraries and load data. You are not required to make any changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for manipulating directory paths\n",
    "import os\n",
    "\n",
    "# Scientific and vector computation for python\n",
    "import numpy as np\n",
    "\n",
    "# Plotting library\n",
    "import matplotlib.pyplot as pyplot\n",
    "\n",
    "# Optimization module in scipy\n",
    "from scipy import optimize\n",
    "\n",
    "# library written for this exercise providing additional functions\n",
    "import utils\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# tells matplotlib to embed plots within the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load breast cancer data from sklearn.datasets\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y = True)\n",
    "\n",
    "# We create a small test set (x_test, y_test) as a subset from dataset to use later for prediction\n",
    "X, x_test, y, y_test = train_test_split(X, y, test_size = 0.05, random_state = 42) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "In the cells below, implement **regularized logistic regression classifier** by writing code for computing:\n",
    "- `sigmoid function`\n",
    "- `cost function` regularized logistic regression\n",
    "- `gradient descent` regularized logistic regression\n",
    "\n",
    "Before implementing these functions, first print the shape of features (X), target (y) and size of training examples. \n",
    "\n",
    "At the end, test your implementation using initialized weights `w` of zeros and `lambda_` value of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(540, 30) (540,)\n",
      "(29, 30) (29,)\n"
     ]
    }
   ],
   "source": [
    "# Print shape of X and y arrays\n",
    "# ====================== YOUR CODE HERE ==================\n",
    "print(X.shape , y.shape)\n",
    "\n",
    "# Print the number of training examples\n",
    "# ====================== YOUR CODE HERE ==================\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Compute sigmoid function given the input z\n",
    "    \"\"\"\n",
    "    # Return correct value of g\n",
    "    g = np.zeros(z.shape)\n",
    "    \n",
    "    # ====================== YOUR CODE HERE ======================\n",
    "    \n",
    "    e = np.exp(1)\n",
    "    \n",
    "    g = 1 / (1 + (e**(-1 *z)))\n",
    "\n",
    "    # =============================================================\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costFunctionReg(w, X, y, lambda_):\n",
    "    \"\"\"\n",
    "    Compute cost for regularized logistic regression. \n",
    "     \n",
    "    \"\"\"\n",
    "    m = y.size  # number of training examples\n",
    "\n",
    "    # You need to return the following variables correctly \n",
    "    J = 0\n",
    "    # ===================== YOUR CODE HERE ======================\n",
    "    z = np.dot(X,w)\n",
    "    sigm = sigmoid(z)\n",
    "    J = (np.sum((-1*np.dot(y,np.log(sigm))) + (-1*np.dot((1-y),np.log(1-sigm))))/m) + ((lambda_/(2*m))*np.sum(np.power(w[1:], 2)))\n",
    "    \n",
    "    # =======\n",
    "    # =============================================================\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientReg(w, X, y, lambda_):\n",
    "    \"\"\"\n",
    "    Compute gradient for regularized logistic regression. \n",
    "    \n",
    "    \"\"\"\n",
    "    grad = np.zeros(w.shape)\n",
    "\n",
    "    # ===================== YOUR CODE HERE ======================\n",
    "    z = np.dot(X,w)\n",
    "    sigm = sigmoid(z)\n",
    "    for j in range (grad.size):\n",
    "        grad[j] = np.sum((sigm - y) * X[:, j]) / m \n",
    "        if j > 0: grad[j] +=(lambda_/m)*w[j]\n",
    "    \n",
    "    \n",
    "    # =============================================================\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the data matrix appropriately, and add ones for the intercept term\n",
    "m, n = X.shape\n",
    "\n",
    "# Add intercept term to X\n",
    "X = np.concatenate([np.ones((m, 1)), X], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at initial w (zeros): 0.693\n",
      "Expected cost (approx): 0.693\n",
      "\n",
      "Gradient at initial w (zeros) - first five values only:\n",
      "\t[-0.1278, -0.5714, -1.5977, -3.1023, 35.9895]\n",
      "Expected gradients (approx) - first five values only:\n",
      "\t[-0.1278, -0.5714, -1.5977, -3.1023, 35.9895]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test your implementation by computing cost for initialized weights of zeros and lambda_= 1\n",
    "\n",
    "# Set regularization parameter\n",
    "lambda_ = 1\n",
    "\n",
    "# Initialize fitting parameters\n",
    "initial_w = np.zeros(n + 1)\n",
    "\n",
    "cost = costFunctionReg(initial_w, X, y, lambda_)\n",
    "grad = gradientReg(initial_w, X, y, lambda_)\n",
    "\n",
    "print('Cost at initial w (zeros): {:.3f}'.format(cost))\n",
    "print('Expected cost (approx): 0.693\\n')\n",
    "\n",
    "print('Gradient at initial w (zeros) - first five values only:')\n",
    "print('\\t[{:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}]'.format(*grad[:5]))\n",
    "\n",
    "print('Expected gradients (approx) - first five values only:')\n",
    "print('\\t[-0.1278, -0.5714, -1.5977, -3.1023, 35.9895]\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "#### The next cell implements code for learning the weights. Execute the cell, and evaluate the quality of the learned weights that are found. Notice that  `lambda_` is initiated with 10.\n",
    "\n",
    "#### You will evaluate in two ways:\n",
    "1. ##### using `predict` function on test set (x_test) and printing the predicted results and actual values (y_test).  \n",
    "The `predict` function should produce “1” or “0” predictions given a dataset and a learned parameter vector  `w`.\n",
    "\n",
    "\n",
    "2. ##### checking and printinf the accuracy of the prediction in the training dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at w found by optimize.minimize: 0.124\n",
      "Expected cost (approx): 0.684\n",
      "\n",
      "w:\n",
      "\t[24.107, 0.001, -0.016]\n"
     ]
    }
   ],
   "source": [
    "## You are not required to make changes\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Initialize fitting parameters\n",
    "m, n = X.shape\n",
    "\n",
    "initial_w = np.zeros(X.shape[1])\n",
    "\n",
    "# Set regularization parameter\n",
    "lambda_ = 100\n",
    "\n",
    "res = minimize(costFunctionReg, \n",
    "               initial_w, \n",
    "               (X,y, lambda_), \n",
    "               method='TNC', \n",
    "               jac=gradientReg, \n",
    "               options={'maxiter':100})\n",
    "\n",
    "# the fun property of `OptimizeResult` object returns\n",
    "# the value of costFunction at optimized w\n",
    "cost = res.fun\n",
    "\n",
    "# the optimized w is in the x property\n",
    "w = res.x\n",
    "\n",
    "# Printing w to screen\n",
    "print('Cost at w found by optimize.minimize: {:.3f}'.format(cost))\n",
    "print('Expected cost (approx): 0.684\\n');\n",
    "\n",
    "print('w:')\n",
    "print('\\t[{:.3f}, {:.3f}, {:.3f}]'.format(*w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, X):\n",
    "    \"\"\"\n",
    "    Predict whether the label is 0 or 1 using learned logistic regression.\n",
    "    Computes the predictions for X using a threshold at 0.5 \n",
    "    (i.e., if sigmoid(w.T*x) >= 0.5, predict 1)\n",
    "    \n",
    "    Instructions\n",
    "    ------------\n",
    "    Complete the following code to make predictions using your learned \n",
    "    logistic regression parameters.You should set p to a vector of 0's and 1's    \n",
    "    \"\"\"\n",
    "    \n",
    "    m, n = X.shape # Number of training examples\n",
    "    \n",
    "    # You need to return the following variables correctly\n",
    "    p = np.empty(m) # Predictions and 0 or 1 for each row in X\n",
    "\n",
    "    # ====================== YOUR CODE HERE ======================\n",
    "    p = sigmoid(np.dot(X,w))\n",
    "    for i in range (m):\n",
    "        if p[i] >= 0.5:\n",
    "            p[i] = 1\n",
    "        if p[i] < 0.5:\n",
    "            p[i] = 0\n",
    "\n",
    "    # ============================================================\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "## You are not required to make changes\n",
    "# Add intercept term to test set data (x_test)\n",
    "x_test = np.concatenate([np.ones((x_test.shape[0], 1)), x_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values: \n",
      " [1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1.]\n",
      "Actual values: \n",
      " [1 0 0 1 1 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Print probabilites and predictions on test_set. For predictions, use predict function above\n",
    "\n",
    "# ====================== YOUR CODE HERE ======================\n",
    "predicted_values_test = predict(w,x_test)\n",
    "print('Predicted values: \\n', predicted_values_test)\n",
    "\n",
    "# ============================================================\n",
    "\n",
    "print('Actual values: \\n', y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  96.55172413793103\n"
     ]
    }
   ],
   "source": [
    "#  Compute accuracy on the training dataset\n",
    "# ====================== YOUR CODE HERE ======================\n",
    "print('Train Accuracy: ', (np.mean(predicted_values_test == y_test) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Change the value of initiailized lambda_ to 0. Has the new value of Train Accuracy improved? Briefly explain why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit the solution\n",
    "\n",
    "When you completed the excercise, download (form File menu) this file as a jupyter Notebook file (.ipynb) and uplaod this file in the CANVAS \n",
    "\n",
    "*By writing down my name I declare that I have done the assignements myself\n",
    "\n",
    "* First Name  Last Name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
